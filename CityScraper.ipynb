{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scrapping cities data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a generic read from the url and target the area to be parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bsoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "urlbase = 'https://en.wikipedia.org'\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population'\n",
    "\n",
    "\n",
    "def readUrl(url):\n",
    "    html = urlopen(url)\n",
    "    bsObj = bsoup(html.read(),'html.parser')\n",
    "    return bsObj\n",
    "\n",
    "def infoBoxScraper(link):\n",
    "    bsObj = readUrl(link)\n",
    "    target_table = bsObj.find_all('table',{\"class\":\"infobox\"})[0]\n",
    "    return target_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are calling all the main url and using beautifull soup library to detect the target table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_page = readUrl(url)\n",
    "# locating the target page into html formate\n",
    "table = main_page.find_all('table',{\"class\":\"wikitable sortable\"})[0]\n",
    "# locating target table which contains all cities name\n",
    "\n",
    "rows = table.find_all('tr')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the we understand the data and each cells how data is stored and formulate our techniques to extract the necessary information. There is always a pattern in an the same columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York City, Los Angeles, Chicago, Houston, Phoenix, Philadelphia, San Antonio, San Diego, Dallas, San Jose, Austin, Jacksonville, Fort Worth, Columbus, San Francisco, Charlotte, Indianapolis, Seattle, Denver, Washington, D.C., Boston, El Paso, Detroit, Nashville, Portland, Memphis, Oklahoma City, Las Vegas, Louisville, Baltimore, Milwaukee, Albuquerque, Tucson, Fresno, Mesa, Sacramento, Atlanta, Kansas City, Colorado Springs, Miami, Raleigh, Omaha, Long Beach, Virginia Beach, Oakland, Minneapolis, Tulsa, Arlington, Tampa, New Orleans, Wichita, Cleveland, Bakersfield, Aurora, Anaheim, Honolulu, Santa Ana, Riverside, Corpus Christi, Lexington, Stockton, Henderson, Saint Paul, St. Louis, Cincinnati, Pittsburgh, Greensboro, Anchorage, Plano, Lincoln, Orlando, Irvine, Newark, Toledo, Durham, Chula Vista, Fort Wayne, Jersey City, St. Petersburg, Laredo, Madison, Chandler, Buffalo, Lubbock, Scottsdale, Reno, Glendale, Gilbert, Winstonâ€“Salem, North Las Vegas, Norfolk, Chesapeake, Garland, Irving, Hialeah, Fremont, Boise, Richmond, Baton Rouge, Spokane, Des Moines, Tacoma, San Bernardino, Modesto, Fontana, Santa Clarita, Birmingham, Oxnard, Fayetteville, Moreno Valley, Rochester, Glendale, Huntington Beach, Salt Lake City, Grand Rapids, Amarillo, Yonkers, Aurora, Montgomery, Akron, Little Rock, Huntsville, Augusta, Port St. Lucie, Grand Prairie, Columbus, Tallahassee, Overland Park, Tempe, McKinney, Mobile, Cape Coral, Shreveport, Frisco, Knoxville, Worcester, Brownsville, Vancouver, Fort Lauderdale, Sioux Falls, Ontario, Chattanooga, Providence, Newport News, Rancho Cucamonga, Santa Rosa, Oceanside, Salem, Elk Grove, Garden Grove, Pembroke Pines, Peoria, Eugene, Corona, Cary, Springfield, Fort Collins, Jackson, Alexandria, Hayward, Lancaster, Lakewood, Clarksville, Palmdale, Salinas, Springfield, Hollywood, Pasadena, Sunnyvale, Macon, Kansas City, Pomona, Escondido, Killeen, Naperville, Joliet, Bellevue, Rockford, Savannah, Paterson, Torrance, Bridgeport, McAllen, Mesquite, Syracuse, Midland, Pasadena, Murfreesboro, Miramar, Dayton, Fullerton, Olathe, Orange, Thornton, Roseville, Denton, Waco, Surprise, Carrollton, West Valley City, Charleston, Warren, Hampton, Gainesville, Visalia, Coral Springs, Columbia, Cedar Rapids, Sterling Heights, New Haven, Stamford, Concord, Kent, Santa Clara, Elizabeth, Round Rock, Thousand Oaks, Lafayette, Athens, Topeka, Simi Valley, Fargo, Norman, Columbia, Abilene, Wilmington, Hartford, Victorville, Pearland, Vallejo, Ann Arbor, Berkeley, Allentown, Richardson, Odessa, Arvada, Cambridge, Sugar Land, Beaumont, Lansing, Evansville, Rochester, Independence, Fairfield, Provo, Clearwater, College Station, West Jordan, Carlsbad, El Monte, Murrieta, Temecula, Springfield, Palm Bay, Costa Mesa, Westminster, North Charleston, Miami Gardens, Manchester, High Point, Downey, Clovis, Pompano Beach, Pueblo, Elgin, Lowell, Antioch, West Palm Beach, Peoria, Everett, Ventura, Centennial, Lakeland, Gresham, Richmond, Billings, Inglewood, Broken Arrow, Sandy Springs, Jurupa Valley, Hillsboro, Waterbury, Santa Maria, Boulder, Greeley, Daly City, Meridian, Lewisville, Davie, West Covina, League City, Tyler, Norwalk, San Mateo, Green Bay, Wichita Falls, Sparks, Lakewood, Burbank, Rialto, Allen, El Cajon, Las Cruces, Renton, Davenport, South Bend, Vista, Tuscaloosa, Clinton, Edison, Woodbridge, San Angelo, Kenosha, Vacaville, "
     ]
    }
   ],
   "source": [
    "data={'city':[], 'state':[], 'population_2018':[], 'population_2010':[], 'change':[],\n",
    "      'area_in_miles':[], 'area_in_kms':[], 'population_density_in_miles':[], 'population_density_in_kms':[],\n",
    "     'location':[],'wiki_url':[],'mayor':[],'website':[]}\n",
    "header = (list) (data.keys())\n",
    "for row in rows[1:]:\n",
    "    cells = row.find_all('td')\n",
    "    \n",
    "    if cells[1].i and cells[1].i.a:\n",
    "        wikiurl = urlbase+cells[1].i.a['href']\n",
    "    else :\n",
    "        wikiurl = urlbase+cells[1].a['href']\n",
    "    data['wiki_url'].append(wikiurl)\n",
    "    \n",
    "    for i in range(1,len(cells)):\n",
    "        cell = cells[i]\n",
    "        if i == 1:\n",
    "            while str(cell)[0] == '<':\n",
    "                cell = cell.contents[0]\n",
    "            data[header[i-1]].append(cell)\n",
    "            print(cell,end=\", \")\n",
    "        elif i == 7 or i==9:\n",
    "            nums = re.findall('[\\.\\d]+',re.sub(',','',cell.contents[0]))\n",
    "            if len(nums)>0:\n",
    "                cell = float(nums[0])\n",
    "            else:\n",
    "                cell = None\n",
    "            data[header[i-1]].append(cell)\n",
    "#             print(cell,end=\", \")\n",
    "        elif i == 10:\n",
    "            res = ''\n",
    "            res +=cell.contents[0].contents[0].contents[0].contents[0].contents[0].contents[0].contents[0]+' '\n",
    "            res += cell.contents[0].contents[0].contents[0].contents[0].contents[0].contents[2].contents[0]\n",
    "            data[header[i-1]].append(res)\n",
    "#             print(res)\n",
    "        else:\n",
    "            while str(cell)[0] == '<':\n",
    "\n",
    "                if cell.contents[-1] == '\\n' :\n",
    "                    cell = cell.contents[-2]\n",
    "                else:\n",
    "                    cell = cell.contents[-1]\n",
    "            cell = cell.strip('\\n')\n",
    "            \n",
    "            if i in [3,4,5,6,8]:\n",
    "                nums = re.findall('[\\.\\d]+',re.sub(',','',cell))\n",
    "                if len(nums)>0:\n",
    "                    cell = float(nums[0])\n",
    "                else:\n",
    "                    cell = None\n",
    "            data[header[i-1]].append(cell)\n",
    "#             print(cell,end=\", \")\n",
    "    \n",
    "    #  here we want to use the information learned from the wiki links of each cities and \n",
    "    #  use it to navigate to infobox of each city\n",
    "    table = infoBoxScraper(wikiurl)\n",
    "    website = None\n",
    "    mayor = None\n",
    "    for cell in table.contents[0].contents:\n",
    "        var = (re.sub('<[^<]+?>',\"****\",str(cell)))\n",
    "        #  here we assume **** would be a unique pattern and not consist in the infobox data\n",
    "        info = [x for x in (var.split('****')) if x !=\"\"]\n",
    "        if 'Website' in info:\n",
    "            info.remove('Website')\n",
    "            for i in info:\n",
    "                m = re.findall('[\\w]+\\.[\\w\\./-]+',i)\n",
    "                if len(m)>0:\n",
    "                    website = m[0]\n",
    "                    break\n",
    "            # many time the info box stores a href link which we are unable to detect             \n",
    "#             print('website found',website)\n",
    "        elif 'Mayor' in info:\n",
    "            info.pop(0)\n",
    "            info.remove('Mayor')\n",
    "            mayor = info[0]\n",
    "#             print('Mayor found ',mayor )\n",
    "    data['mayor'].append(mayor)\n",
    "    data['website'].append(website)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to csv file so that we can upload to googles bigQuerry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.DataFrame.from_dict(data)\n",
    "dataframe.to_csv('cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
